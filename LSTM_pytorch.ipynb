{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/zankyo/Desktop/yamamoto/model/lstm20201116_170017\n"
     ]
    }
   ],
   "source": [
    "outname =\"lstm\"\n",
    "\n",
    "outdir = 'C:/Users/zankyo/Desktop/yamamoto/model/' +outname+ now.strftime('%Y%m%d_%H%M%S')\n",
    "print(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_len = 2**15\n",
    "usedata_num = 15000\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe329c383464054aae1dab26eee5da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642ea53200ce46dd8899763dfd81e7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zankyo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ..\\aten\\src\\ATen\\native\\Copy.cpp:162.)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "datasets_dir = 'C:/Users/zankyo/Desktop/yamamoto/datasets/datasets129x257.npz'\n",
    "datasets = np.load(datasets_dir)\n",
    "\n",
    "data, label = datasets['data'], datasets['label']\n",
    "\n",
    "data_list = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    data_list.append(data[i])\n",
    "    \n",
    "label_list = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    label_list.append(label[i])\n",
    "    \n",
    "tensor_data = torch.stack([torch.Tensor(i) for i in data_list])\n",
    "tensor_label = torch.stack([torch.Tensor(i) for i in label_list])\n",
    "\n",
    "mydataset = utils.TensorDataset(tensor_data,tensor_label)\n",
    "\n",
    "train_dataset, val_dataset,test_dataset = utils.random_split(mydataset,[12000,2500,500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "train_dataloader = utils.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "val_dataloader = utils.DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_dataloader = utils.DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "#辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\":train_dataloader,\n",
    "                    \"val\":val_dataloader,\n",
    "                    \"test\":test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動作の確認\n",
    "\n",
    "Batch, Freq(Feature), Time(Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 129, 257])\n",
      "torch.Size([50, 129, 257])\n"
     ]
    }
   ],
   "source": [
    "batch_iterator = iter(dataloaders_dict[\"train\"])\n",
    "datas,labels=next(batch_iterator)\n",
    "print(datas.size())\n",
    "print(labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net Work Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_size = x_train.shape[1]\n",
    "sequence_len = x_train.shape[2]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net,self).__init__()\n",
    "        self.seq_len = sequence_len\n",
    "        self.feature_size = feat_size\n",
    "        self.output_size = feat_size\n",
    "        self.hidden_layer_size = 150 #隠れ層のサイズ\n",
    "        self.lstm_layers = 3 #LSTMのレイヤー数\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.feature_size,\n",
    "                           self.hidden_layer_size,\n",
    "                           num_layers = self.lstm_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_layer_size,self.output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def init_hidden_cell(self,batch_size): #LSTMの隠れ層hidden、記憶セルcellを初期化\n",
    "        hidden = torch.zeros(self.lstm_layers,batch_size,self,hidden_layer_size)\n",
    "        cell = torch.zeros(self.lstm_layers,batch_size,self,hidden_layer_size)\n",
    "        return hidden, cell\n",
    "    \n",
    "    def forword(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        self.hidden_cell = self.init_hidden_cell(batch_size)\n",
    "        # 入力は(Batch, Seqence, Feature)\n",
    "#         x = x.view(batch_size, self.seq_len,self.feature_size)\n",
    "        x = x.permute(0,2,1) # 次元の入れ替え\n",
    "        # Batch, Freq(Feature), Time(Sequence)になってるので\n",
    "        # 入力は(Batch, Seqence, Feature)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x,self.hidden_cell)\n",
    "        \n",
    "        x = h_n[-1,:,:]\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        x=self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lstm): LSTM(129, 150, num_layers=3)\n",
       "  (fc): Linear(in_features=150, out_features=129, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "net.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss #平均絶対値誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化手法の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimaizer = optim.Adam(net.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・検証の実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, device, num_epochs):\n",
    "    \n",
    "    #epochループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch{}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "        \n",
    "        #epochごとの学習と検証ループ\n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                net.train() #モデルをトレーニングモードに\n",
    "            else:\n",
    "                net.eval() #モデルを検証モードに\n",
    "                \n",
    "            epoch = 0.0 #epochの損失和\n",
    "            epoch_corrects = 0 #epochの正解数\n",
    "            \n",
    "            # 未学習時の検証性能を確かめるためepoch=0での訓練はスキップ\n",
    "            if (epoch == 0) and (phase=='train'):\n",
    "                continue\n",
    "                \n",
    "            # データローダーからミニバッチを取り出す\n",
    "            for i,(inputs, labels) in tqdm(enumerate(dataloaders_dict[phase])):\n",
    "                \n",
    "                #GPUにキャスト\n",
    "                inputs = inputs.to(device)\n",
    "                labels = inputs.to(device)\n",
    "                \n",
    "                #optimizerを初期化\n",
    "                optimaizer.zero_grad()\n",
    "                \n",
    "                # 順伝搬計算(forword)\n",
    "                with torch.set_grad_enabled(phase == 'train'): #訓練モードのみ勾配計算\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels) #損失の計算\n",
    "                    _, preds = torch.max(outputs,1) #ラベルの予測\n",
    "                    \n",
    "                #訓練時は逆伝搬(バックプロパゲーション)\n",
    "                if phasa == 'train':\n",
    "                    loss.backward()\n",
    "                    optimaizer.step()\n",
    "                    \n",
    "                # Iteration結果の計算\n",
    "                # lossの計算を更新\n",
    "                epoch_loss += loss.item() * input.size(0)\n",
    "                # 正解数の合計を更新\n",
    "                epoch_corrects += touch.sum(preds == labels.data)\n",
    "            \n",
    "            # epochごとのlossと正答率を表示\n",
    "            epoch_loss = epoch_loss/len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double()/len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            print('{}Loss: {:.4f} Acc:{:,.4f}'.format(phase, epoch_loss,epoch_acc))\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・検証の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/3\n",
      "-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23cfc1587d143e08abbbeb3c2e8a291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-2d54d30af647>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-659720f4a525>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(net, dataloaders_dict, criterion, device, num_epochs)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;31m# 順伝搬計算(forword)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#訓練モードのみ勾配計算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#損失の計算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#ラベルの予測\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "train_model(net, dataloaders_dict, criterion, device, num_epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
